{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystk2_gymnasium import AgentSpec\n",
    "import gymnasium as gym\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sac_torch import AgentSac\n",
    "from utils import plot_learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectKeysWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, selected_keys):\n",
    "        super().__init__(env)\n",
    "        self.selected_keys = selected_keys\n",
    "\n",
    "        # Filter the original observation space\n",
    "        new_obs_space = {key: env.observation_space[key] for key in selected_keys}\n",
    "        self.observation_space = gym.spaces.Dict(new_obs_space)\n",
    "        self.obs_len = ???\n",
    "\n",
    "    def observation(self, observation):\n",
    "        \"\"\"Filter the observation to only return selected keys.\"\"\"\n",
    "        return {key: observation[key] for key in self.selected_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Setup the environment\n",
    "\n",
    "player_name = \"smail_gaetan_kart\"\n",
    "env_name = \"supertuxkart/flattened_continuous_actions-v0\"\n",
    "n_envs = 1\n",
    "n_steps = 3000\n",
    "max_episode_steps = 200\n",
    "\n",
    "def create_env(render_mode):\n",
    "    env = gym.make(\n",
    "        env_name,\n",
    "        render_mode=render_mode, # human for video, else None \n",
    "        agent=AgentSpec(use_ai=False, name=player_name), # use_ai=False for using the \"action\" line of the workspace\n",
    "    )\n",
    "    # env = ContinuousObservationWrapper(env)\n",
    "    selected_keys = {'center_path', 'center_path_distance', 'front', 'velocity'}\n",
    "    env = SelectKeysWrapper(env, selected_keys)\n",
    "    # env = gym.wrappers.TimeLimit(env, max_episode_steps=max_episode_steps)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m envs \u001b[39m=\u001b[39m [create_env(\u001b[39mNone\u001b[39;00m) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_envs\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)]\u001b[39m+\u001b[39m[create_env(\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m      2\u001b[0m agent \u001b[39m=\u001b[39m AgentSac(input_dims\u001b[39m=\u001b[39menvs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mobservation_space\u001b[39m.\u001b[39mshape, env\u001b[39m=\u001b[39menvs[\u001b[39m0\u001b[39m],\n\u001b[0;32m----> 3\u001b[0m                 n_actions\u001b[39m=\u001b[39menvs[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49maction_space\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m      5\u001b[0m score_history \u001b[39m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m load_checkpoint \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..:: Antarctica Rendering Engine 2.0 ::..\n"
     ]
    }
   ],
   "source": [
    "envs = [create_env(None) for _ in range(n_envs-1)]+[create_env(\"human\")]\n",
    "agent = AgentSac(input_dims=envs[0].observation_space.shape, env=envs[0],\n",
    "                n_actions=envs[0].action_space.shape[0])\n",
    "\n",
    "score_history = []\n",
    "load_checkpoint = False\n",
    "\n",
    "# if load_checkpoint:\n",
    "#     agent.load_models()\n",
    "#     envs[0].render(mode='human')\n",
    "\n",
    "observations = [envs[i].reset()[0] for i in range(n_envs)]\n",
    "scores = [0]*n_envs\n",
    "scores_history = [[] for _ in range(n_envs)]\n",
    "center_path_distances = []\n",
    "\n",
    "t_choose = 0\n",
    "t_step = 0\n",
    "t_learn = 0\n",
    "print(\"beginning of training\")\n",
    "\n",
    "for k in range(n_steps):\n",
    "    for i in range(n_envs):\n",
    "        t = time.time()\n",
    "        action = agent.choose_action(observations[i])\n",
    "        t_choose += time.time()-t\n",
    "\n",
    "        t = time.time()\n",
    "        observation_, reward, terminated, truncated, info = envs[i].step(action)\n",
    "        print(observation_)\n",
    "        import sys; sys.exit()\n",
    "        center_path_distance = observation_[5]\n",
    "        reward -= abs(center_path_distance)\n",
    "        t_step += time.time() - t\n",
    "\n",
    "        done = terminated or truncated\n",
    "        scores[i] += reward\n",
    "        agent.remember(observations[i], action, reward, observation_, done)\n",
    "\n",
    "        if done:\n",
    "            envs[i] = create_env(envs[i].render_mode)\n",
    "            observations[i] = envs[i].reset()[0]\n",
    "\n",
    "        t = time.time()\n",
    "        if not load_checkpoint:\n",
    "            agent.learn()\n",
    "        t_learn += time.time()-t\n",
    "\n",
    "        observations[i] = observation_\n",
    "        scores_history[i].append(scores[i])\n",
    "\n",
    "        if k%50==49:\n",
    "            plot_learning_curve(list(range(k+1)), scores_history[i], \"plots/stk_scores.png\")\n",
    "        if k==n_steps-1:\n",
    "            envs[i].close()\n",
    "\n",
    "print(f\"{t_choose = } | {t_step = } | {t_learn = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'center_path', 'center_path_distance', 'front', 'velocity'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs[0].selected_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dict('attachment': Discrete(10), 'attachment_time_left': Box(0.0, inf, (1,), float32), 'aux_ticks': Box(0.0, inf, (1,), float32), 'center_path': Box(-inf, inf, (3,), float32), 'center_path_distance': Box(-inf, inf, (1,), float32), 'distance_down_track': Box(-inf, inf, (1,), float32), 'energy': Box(0.0, inf, (1,), float32), 'front': Box(-inf, inf, (3,), float32), 'items_position': Box(-inf, inf, (5, 3), float32), 'items_type': MultiDiscrete([7 7 7 7 7]), 'jumping': Discrete(2), 'karts_position': Box(-inf, inf, (5, 3), float32), 'max_steer_angle': Box(-1.0, 1.0, (1,), float32), 'paths_distance': Box(0.0, inf, (5, 2), float32), 'paths_end': Box(-inf, inf, (5, 3), float32), 'paths_start': Box(-inf, inf, (5, 3), float32), 'paths_width': Box(0.0, inf, (5, 1), float32), 'phase': Discrete(4), 'powerup': Discrete(11), 'shield_time': Box(0.0, inf, (1,), float32), 'skeed_factor': Box(0.0, inf, (1,), float32), 'velocity': Box(-inf, inf, (3,), float32)),\n",
       " {'acceleration': array([0.16754398], dtype=float32),\n",
       "  'steer': array([-0.30473718], dtype=float32)})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs[0].observation_space, envs[0].action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env in envs:\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36744e71f352e8024a9382f8cce87855ab2ab8229a59ebe763a00ce39fec0cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
